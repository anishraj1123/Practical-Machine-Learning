---
title: "Practical Machine Learning-Prediction Assignment Writeup"
author: "Anish Raj"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE, warning=FALSE)
```

## Background & Objective

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively.

These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks.One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The project objective is to predict the manner in which they did the exercise. "classe" variable in the training set is the experiment outcome. 

## Data Source

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 

## Loading relevant libraries

```{r lib}
library(knitr)
library(caret)
library(rattle)
library(rpart)
library(ggplot2)
library(randomForest)
set.seed(1234)
```

## Data Loading & Cleaning

```{r pml}
train <- read.csv("./pml-training.csv")
test <- read.csv("./pml-testing.csv")
dim(train);dim(test)
```
### Cleaning data
Data cleaning using the following criterias :
- Remove columns with mostly (>95%) NAs
- Remove columns with Near Zero variance
- Remove information only columns

```{r clean}
# remove columns that are mostly NA
NAFlag <- sapply(train, function(x) mean(is.na(x))) > 0.95
train <- train[, NAFlag==FALSE]
test <- test[, NAFlag==FALSE]
dim(train);dim(test)

# remove columns with Nearly Zero Variance
NZV <- nearZeroVar(train)
train <- train[, -NZV]
test <- test[, -NZV]
dim(train);dim(test)

# remove information only columns (columns 1 to 5)
train <- train[, -(1:5)]
test <- test[, -(1:5)]
dim(train);dim(test)
```

### Partitioning the training data for cross validation (using 60% for training and 40% for validation)

```{r part}
set.seed(1234)
inTrain <- createDataPartition(train$classe, p=0.6, list=FALSE)
trainT <- train[inTrain,]
trainV <- train[-inTrain,]
dim(trainT);dim(trainV);dim(test)
```

## Prediction model buidling using Decision Tree, Random Forest & Generalized Boosted Model(GBM)

```{r model}
## Model using Decision Tree
set.seed(1234)
modFitDT  <- rpart(classe ~ ., data=trainT, method="class")
fancyRpartPlot(modFitDT)

## prediction using validation set on Decison Tree model
prediction <- predict(modFitDT, newdata = trainV,type = "class")
confusionMatrix(prediction, trainV$classe)

## Model using Random Forest
set.seed(1234)
modFitRF <- randomForest(classe ~ ., data = trainT)
modFitRF

## prediction using validation set on Random Forest model
prediction <- predict(modFitRF, newdata = trainV)
confusionMatrix(prediction, trainV$classe)

## Model using Generalized Boosted Model(GBM)
set.seed(1234)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGBM <- train(classe ~ .,method="gbm",data = trainT,verbose=FALSE,trControl = controlGBM)
modFitGBM$finalModel

## prediction using validation set on Generalized Boosted Model(GBM)
prediction <- predict(modFitGBM, newdata = trainV)
confusionMatrix(prediction, trainV$classe)
```

## Model Selection & Prediction on test data provided

The accuracy of the 3 models are as follows : Decision Tree : 0.7239, Random Forest : 0.9964 , Generalized Boosted Model(GBM) : 0.9871

Random forest is chosen as the final model for prediction based on highest accuracy and for Random Forest model OOB estimate of  error rate (using the train subset in training set) is 0.44% and Out of sample error (using the validaton subset in the training set) is 0.36%

### Prediction on the final test data having 20 samples is as follows

```{r predict}
predictiontest <- predict(modFitRF, newdata=test)
predictiontest
```




